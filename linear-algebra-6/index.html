<!DOCTYPE html>
<html>
  <head>
    <title><复习向>线性代数之矩阵的特征值、特征向量、特征矩阵、迹 – Wyman的技术博客 – 伪技术宅，兴趣点：服务器编程、游戏开发、人工智能</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
    <meta name="baidu-site-verification" content="0OpfO1OtHA" />
    
    <meta name="description" content="定义

设A是数域F上的n阶矩阵，如果存在数域F中的一个数\(\lambda \)与数域上F的非零向量\(\alpha \)，使得：
\[ A\alpha = \lambda \alpha \]
则称\(\lambda \)为A的一个特征值(根)(eigenvalue)，称\(\alpha \)为A的属于特征值\(\lambda \)的特征向量(eigenvector)。

\( A\alpha \)和\(\alpha \)平行（即在同一个直线上。

\(\lambda E - A\)为A的特征矩阵，行列式\(f(\lambda ) = |\lambda E - A|\)为A的特征多项式，\(|\lambda E - A| = 0\)为A的特征方程,\((\lambda E - A)X=0\)是A关于该\(\lambda \)的齐次线性方程组。

A的主对角线上元素之和称为A的迹(trace)，记为tr(A)，即

\[ tr(A) = a_{11} + a_{11} + \cdots + a_{nn} \]

迹和特征值有很重要的联系：

\[ tr(A) = \lambda _{1} + \lambda _{2} + \cdots + \lambda _{n} \]

迹还和A的行列式有关系：

\[ |A| = \lambda _{1}\lambda _{2}\cdots \lambda _{n} \]

A的全部特征值和特征向量的求法


计算A的特征多项式
求特征方程的全部根，即矩阵A的全部特征值
对于A的每一个特征值\(\lambda \)，求其相应的齐次线性方程组的一个基础解系\(\eta _{1},\eta _{2},\cdots \eta _{n-r}\)，其中\(r=r(\lambda E - A)\)，即r为矩阵A的特征矩阵的秩，A的属于该\(\lambda \)的全部特征向量为:
\[ k_{1}\eta _{1} + k_{2}\eta _{2} + \cdots + k_{n-r}\eta _{n-r} \]
其中\(k_{1},k_{2},\cdots ,k_{n-r}\)是数域F上的一组不全为零的任意常数。


特征值的性质


\(\lambda _{n} \)为矩阵\(A_{n} \)的特征值（n为正整数）
A可逆时，\(1/\lambda \)为\(A^{-1}\)的特征值
矩阵A与其转置矩阵\(A^{T}\)有相同的特征值
\(k\lambda \)是矩阵kA的特征值(k是任意常数)。


迹的性质


\( tr(A + B) = tr(A) + tr(B) \)
\( tr(kA) = k\cdot tr(A) \)
\( tr(A^{T}) = tr(A) \)
\( tr(AB) = tr(BA) \)
\( tr(ABC) = tr(BCA) = tr(CAB) \)
设A、B为n阶方阵，P为n阶可逆矩阵，且\(P^{-1}AP = B \)，则有\(tr(A) = tr(B)\)


当A为投影矩阵P时

因为投影矩阵P可以把一个向量b投影到一个空间的某一个向量，也就是\(Pb = p\)，这个式子和\( A\alpha = \lambda \alpha \)有一致的地方。

那么P的特征向量是什么呢？前面已经说到，\( A\alpha \)和\( \alpha \)是平行关系，那么就是说，如果b在P的列空间之外，b就不是P的特征向量，当b在P的列空间内时，b是P的特征向量。

比如当P对应一个平面时，这个平面内的任意一个向量x都是特征向量（因为\(Px = x\)，P作用于x后还是得到x)

又因为\(Px = x = 1\cdot x\)，所以P的一个特征值是1。

但是，P还有其他的特征值。当向量x正交于P的列空间时，有\(Px = 0 \)。所以P的另一个特征值为0。

当A为旋转矩阵Q时

因为旋转矩阵可以改变一个向量的方向，那么这个矩阵是否有特征值？事实是有的，但是是复数。

\[ Q =  \left[ \begin{matrix} cos(90)&amp;-sin(90)\\ sin(90)&amp;cos(90)\\ \end{matrix} \right] =  \left[ \begin{matrix} 0&amp;-1\\ 1&amp;0\\ \end{matrix} \right] \]

\[ |Q| = 0 - (-1) = 1 = \lambda _{1}\lambda _{2} \]
\[ tr(Q) = 0 = \lambda _{1} + \lambda _{2} \]

显然，\( \lambda _{1}\lambda _{2}\)无实数域的解，但是有复数解i和-i。

A的对角化，特征值的一种解法

设n阶方阵A存在n个线性无关的特征向量\(x_{i}\)，将这n个特征向量组成方阵S(也称为特征向量矩阵），则有：

\[ AS = A \left[ \begin{matrix} x_{1}&amp;x_{2}&amp;\cdots &amp;x_{n}\\ \end{matrix} \right] =  \left[ \begin{matrix} \lambda _{1}x_{1}&amp;\lambda _{2}x_{2}&amp;\cdots &amp;\lambda _{n}x_{n}\\ \end{matrix} \right] \] 
\[    =  \left[ \begin{matrix} x_{1}&amp;x_{2}&amp;\cdots &amp;x_{n}\\ \end{matrix} \right] \left[ \begin{matrix} \lambda _{1}&amp;0&amp;\cdots &amp;0\\ 0&amp;\lambda _{2}&amp;\cdots &amp;0\\ \vdots &amp;\vdots&amp; \cdots &amp;\vdots\\ 0&amp;0&amp;\cdots &amp;\lambda _{n}\\ \end{matrix} \right] \]
\[ = S\Lambda \]

所以有：

\[ A = S\Lambda S^{-1} \]

这个式子称为A的\(S\Lambda S^{-1}\)分解，或特征分解(Eigendecomposition)。
" />
    <meta property="og:description" content="定义

设A是数域F上的n阶矩阵，如果存在数域F中的一个数\(\lambda \)与数域上F的非零向量\(\alpha \)，使得：
\[ A\alpha = \lambda \alpha \]
则称\(\lambda \)为A的一个特征值(根)(eigenvalue)，称\(\alpha \)为A的属于特征值\(\lambda \)的特征向量(eigenvector)。

\( A\alpha \)和\(\alpha \)平行（即在同一个直线上。

\(\lambda E - A\)为A的特征矩阵，行列式\(f(\lambda ) = |\lambda E - A|\)为A的特征多项式，\(|\lambda E - A| = 0\)为A的特征方程,\((\lambda E - A)X=0\)是A关于该\(\lambda \)的齐次线性方程组。

A的主对角线上元素之和称为A的迹(trace)，记为tr(A)，即

\[ tr(A) = a_{11} + a_{11} + \cdots + a_{nn} \]

迹和特征值有很重要的联系：

\[ tr(A) = \lambda _{1} + \lambda _{2} + \cdots + \lambda _{n} \]

迹还和A的行列式有关系：

\[ |A| = \lambda _{1}\lambda _{2}\cdots \lambda _{n} \]

A的全部特征值和特征向量的求法


计算A的特征多项式
求特征方程的全部根，即矩阵A的全部特征值
对于A的每一个特征值\(\lambda \)，求其相应的齐次线性方程组的一个基础解系\(\eta _{1},\eta _{2},\cdots \eta _{n-r}\)，其中\(r=r(\lambda E - A)\)，即r为矩阵A的特征矩阵的秩，A的属于该\(\lambda \)的全部特征向量为:
\[ k_{1}\eta _{1} + k_{2}\eta _{2} + \cdots + k_{n-r}\eta _{n-r} \]
其中\(k_{1},k_{2},\cdots ,k_{n-r}\)是数域F上的一组不全为零的任意常数。


特征值的性质


\(\lambda _{n} \)为矩阵\(A_{n} \)的特征值（n为正整数）
A可逆时，\(1/\lambda \)为\(A^{-1}\)的特征值
矩阵A与其转置矩阵\(A^{T}\)有相同的特征值
\(k\lambda \)是矩阵kA的特征值(k是任意常数)。


迹的性质


\( tr(A + B) = tr(A) + tr(B) \)
\( tr(kA) = k\cdot tr(A) \)
\( tr(A^{T}) = tr(A) \)
\( tr(AB) = tr(BA) \)
\( tr(ABC) = tr(BCA) = tr(CAB) \)
设A、B为n阶方阵，P为n阶可逆矩阵，且\(P^{-1}AP = B \)，则有\(tr(A) = tr(B)\)


当A为投影矩阵P时

因为投影矩阵P可以把一个向量b投影到一个空间的某一个向量，也就是\(Pb = p\)，这个式子和\( A\alpha = \lambda \alpha \)有一致的地方。

那么P的特征向量是什么呢？前面已经说到，\( A\alpha \)和\( \alpha \)是平行关系，那么就是说，如果b在P的列空间之外，b就不是P的特征向量，当b在P的列空间内时，b是P的特征向量。

比如当P对应一个平面时，这个平面内的任意一个向量x都是特征向量（因为\(Px = x\)，P作用于x后还是得到x)

又因为\(Px = x = 1\cdot x\)，所以P的一个特征值是1。

但是，P还有其他的特征值。当向量x正交于P的列空间时，有\(Px = 0 \)。所以P的另一个特征值为0。

当A为旋转矩阵Q时

因为旋转矩阵可以改变一个向量的方向，那么这个矩阵是否有特征值？事实是有的，但是是复数。

\[ Q =  \left[ \begin{matrix} cos(90)&amp;-sin(90)\\ sin(90)&amp;cos(90)\\ \end{matrix} \right] =  \left[ \begin{matrix} 0&amp;-1\\ 1&amp;0\\ \end{matrix} \right] \]

\[ |Q| = 0 - (-1) = 1 = \lambda _{1}\lambda _{2} \]
\[ tr(Q) = 0 = \lambda _{1} + \lambda _{2} \]

显然，\( \lambda _{1}\lambda _{2}\)无实数域的解，但是有复数解i和-i。

A的对角化，特征值的一种解法

设n阶方阵A存在n个线性无关的特征向量\(x_{i}\)，将这n个特征向量组成方阵S(也称为特征向量矩阵），则有：

\[ AS = A \left[ \begin{matrix} x_{1}&amp;x_{2}&amp;\cdots &amp;x_{n}\\ \end{matrix} \right] =  \left[ \begin{matrix} \lambda _{1}x_{1}&amp;\lambda _{2}x_{2}&amp;\cdots &amp;\lambda _{n}x_{n}\\ \end{matrix} \right] \] 
\[    =  \left[ \begin{matrix} x_{1}&amp;x_{2}&amp;\cdots &amp;x_{n}\\ \end{matrix} \right] \left[ \begin{matrix} \lambda _{1}&amp;0&amp;\cdots &amp;0\\ 0&amp;\lambda _{2}&amp;\cdots &amp;0\\ \vdots &amp;\vdots&amp; \cdots &amp;\vdots\\ 0&amp;0&amp;\cdots &amp;\lambda _{n}\\ \end{matrix} \right] \]
\[ = S\Lambda \]

所以有：

\[ A = S\Lambda S^{-1} \]

这个式子称为A的\(S\Lambda S^{-1}\)分解，或特征分解(Eigendecomposition)。
" />
    
    <meta name="author" content="Wyman的技术博客" />

    
    <meta property="og:title" content="<复习向>线性代数之矩阵的特征值、特征向量、特征矩阵、迹" />
    <meta property="twitter:title" content="<复习向>线性代数之矩阵的特征值、特征向量、特征矩阵、迹" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Wyman的技术博客 - 伪技术宅，兴趣点：服务器编程、游戏开发、人工智能" href="/feed.xml" />

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-65954265-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/linear-algebra-6/',
		  'title': '<复习向>线性代数之矩阵的特征值、特征向量、特征矩阵、迹'
		});
	</script>
	<!-- End Google Analytics -->
	<!-- Baidu Analytics -->
	<script>
		var _hmt = _hmt || [];
		(function() {
		  var hm = document.createElement("script");
		  hm.src = "//hm.baidu.com/hm.js?0dc968591d8c64196a37eca9ca4f86b3";
		  var s = document.getElementsByTagName("script")[0]; 
		  s.parentNode.insertBefore(hm, s);
		})();
	</script>
	<!-- End Baidu Analytics -->

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="http://www.qiujiawei.com/images/avatar.jpg" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Wyman的技术博客</a></h1>
            <p class="site-description">伪技术宅，兴趣点：服务器编程、游戏开发、人工智能</p>
          </div>

          <nav>
            <a href="/">Blog</a>
            <a href="/about">About</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <script type="text/javascript"
            src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<article class="post">
  <h1><复习向>线性代数之矩阵的特征值、特征向量、特征矩阵、迹</h1>
  <h3>Tags: <a href="/tag/matrix.html" rel="tag">matrix</a>, <a href="/tag/linear-algebra.html" rel="tag">linear algebra</a></h3>
  <div class="entry">
    <h2>定义</h2>

<p>设A是数域F上的n阶矩阵，如果存在数域F中的一个数\(\lambda \)与数域上F的非零向量\(\alpha \)，使得：
\[ A\alpha = \lambda \alpha \]
则称\(\lambda \)为A的一个<strong>特征值(根)</strong>(eigenvalue)，称\(\alpha \)为A的属于特征值\(\lambda \)的<strong>特征向量</strong>(eigenvector)。</p>

<p>\( A\alpha \)和\(\alpha \)平行（即在同一个直线上。</p>

<p>\(\lambda E - A\)为A的<strong>特征矩阵</strong>，行列式\(f(\lambda ) = |\lambda E - A|\)为A的<strong>特征多项式</strong>，\(|\lambda E - A| = 0\)为A的<strong>特征方程</strong>,\((\lambda E - A)X=0\)是A关于该\(\lambda \)的<strong>齐次线性方程组</strong>。</p>

<p>A的主对角线上元素之和称为A的<strong>迹</strong>(trace)，记为tr(A)，即</p>

<p>\[ tr(A) = a_{11} + a_{11} + \cdots + a_{nn} \]</p>

<p>迹和特征值有很重要的联系：</p>

<p>\[ tr(A) = \lambda _{1} + \lambda _{2} + \cdots + \lambda _{n} \]</p>

<p>迹还和A的行列式有关系：</p>

<p>\[ |A| = \lambda _{1}\lambda _{2}\cdots \lambda _{n} \]</p>

<h2>A的全部特征值和特征向量的求法</h2>

<ol>
<li>计算A的特征多项式</li>
<li>求特征方程的全部根，即矩阵A的全部特征值</li>
<li>对于A的每一个特征值\(\lambda \)，求其相应的齐次线性方程组的一个基础解系\(\eta _{1},\eta _{2},\cdots \eta _{n-r}\)，其中\(r=r(\lambda E - A)\)，即r为矩阵A的特征矩阵的秩，A的属于该\(\lambda \)的全部特征向量为:
\[ k_{1}\eta _{1} + k_{2}\eta _{2} + \cdots + k_{n-r}\eta _{n-r} \]
其中\(k_{1},k_{2},\cdots ,k_{n-r}\)是数域F上的一组不全为零的任意常数。</li>
</ol>

<h2>特征值的性质</h2>

<ol>
<li>\(\lambda _{n} \)为矩阵\(A_{n} \)的特征值（n为正整数）</li>
<li>A可逆时，\(1/\lambda \)为\(A^{-1}\)的特征值</li>
<li>矩阵A与其转置矩阵\(A^{T}\)有相同的特征值</li>
<li>\(k\lambda \)是矩阵kA的特征值(k是任意常数)。</li>
</ol>

<h2>迹的性质</h2>

<ol>
<li>\( tr(A + B) = tr(A) + tr(B) \)</li>
<li>\( tr(kA) = k\cdot tr(A) \)</li>
<li>\( tr(A^{T}) = tr(A) \)</li>
<li>\( tr(AB) = tr(BA) \)</li>
<li>\( tr(ABC) = tr(BCA) = tr(CAB) \)</li>
<li>设A、B为n阶方阵，P为n阶可逆矩阵，且\(P^{-1}AP = B \)，则有\(tr(A) = tr(B)\)</li>
</ol>

<h2>当A为投影矩阵P时</h2>

<p>因为投影矩阵P可以把一个向量b投影到一个空间的某一个向量，也就是\(Pb = p\)，这个式子和\( A\alpha = \lambda \alpha \)有一致的地方。</p>

<p>那么P的特征向量是什么呢？前面已经说到，\( A\alpha \)和\( \alpha \)是平行关系，那么就是说，如果b在P的列空间之外，b就不是P的特征向量，当b在P的列空间内时，b是P的特征向量。</p>

<p>比如当P对应一个平面时，这个平面内的任意一个向量x都是特征向量（因为\(Px = x\)，P作用于x后还是得到x)</p>

<p>又因为\(Px = x = 1\cdot x\)，所以P的一个特征值是1。</p>

<p>但是，P还有其他的特征值。当向量x正交于P的列空间时，有\(Px = 0 \)。所以P的另一个特征值为0。</p>

<h2>当A为旋转矩阵Q时</h2>

<p>因为旋转矩阵可以改变一个向量的方向，那么这个矩阵是否有特征值？事实是有的，但是是复数。</p>

<p>\[ Q =  \left[ \begin{matrix} cos(90)&amp;-sin(90)\\ sin(90)&amp;cos(90)\\ \end{matrix} \right] =  \left[ \begin{matrix} 0&amp;-1\\ 1&amp;0\\ \end{matrix} \right] \]</p>

<p>\[ |Q| = 0 - (-1) = 1 = \lambda _{1}\lambda _{2} \]
\[ tr(Q) = 0 = \lambda _{1} + \lambda _{2} \]</p>

<p>显然，\( \lambda _{1}\lambda _{2}\)无实数域的解，但是有复数解i和-i。</p>

<h2>A的对角化，特征值的一种解法</h2>

<p>设n阶方阵A存在n个线性无关的特征向量\(x_{i}\)，将这n个特征向量组成方阵S(也称为特征向量矩阵），则有：</p>

<p>\[ AS = A \left[ \begin{matrix} x_{1}&amp;x_{2}&amp;\cdots &amp;x_{n}\\ \end{matrix} \right] =  \left[ \begin{matrix} \lambda _{1}x_{1}&amp;\lambda _{2}x_{2}&amp;\cdots &amp;\lambda _{n}x_{n}\\ \end{matrix} \right] \] 
\[    =  \left[ \begin{matrix} x_{1}&amp;x_{2}&amp;\cdots &amp;x_{n}\\ \end{matrix} \right] \left[ \begin{matrix} \lambda _{1}&amp;0&amp;\cdots &amp;0\\ 0&amp;\lambda _{2}&amp;\cdots &amp;0\\ \vdots &amp;\vdots&amp; \cdots &amp;\vdots\\ 0&amp;0&amp;\cdots &amp;\lambda _{n}\\ \end{matrix} \right] \]
\[ = S\Lambda \]</p>

<p>所以有：</p>

<p>\[ A = S\Lambda S^{-1} \]</p>

<p>这个式子称为A的\(S\Lambda S^{-1}\)分解，或特征分解(Eigendecomposition)。</p>

  </div>

  <div class="date">
    Written on September 26, 2015
  </div>

  
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'qiujiawei';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</article>


    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:voyagingmk@gmail.com"><i class="svg-icon email"></i></a>


<a href="http://github.com/barryclark/jekyll-now"><i class="svg-icon github"></i></a>




<a href="http://twitter.com/voyagingmk"><i class="svg-icon twitter"></i></a>


        </footer>
      </div>
    </div>

  </body>
</html>
